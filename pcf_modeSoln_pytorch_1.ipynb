{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca37c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04921c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# print('start_time: ', start_time)\n",
    "\n",
    "\n",
    "import PySimpleGUI as sg\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasAgg\n",
    "import matplotlib.backends.tkagg as tkagg\n",
    "import tkinter as Tk\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "## Transforms features by scaling each feature to a given range.\n",
    "## This estimator scales and translates each feature individually such that it is in the given range on the training set, i.e. between zero and one.\n",
    "## This transformation is often used as an alternative to zero mean, unit variance scaling.\n",
    "## fit(X[, y])\tCompute the minimum and maximum to be used for later scaling.\n",
    "## transform(X)\tScaling features of X according to feature_range.\n",
    "## fit_transform(X[, y])\tFit to data, then transform it.\n",
    "## inverse_transform(X)\tUndo the scaling of X according to feature_range.\n",
    "scaler1 = MinMaxScaler()  \n",
    "scaler2 = MinMaxScaler()  \n",
    "\n",
    "\n",
    "\n",
    "no_of_output_nodes = 5\n",
    "\n",
    "df_1 = pd.read_excel('pcf_modeSoln_data_1.xlsx', sheetname='SiO2-air-rings-5-dBYp-0.7')\n",
    "datafile_1 = df_1.values                  ## stored data from xlsx file\n",
    "#print(datafile_1)\n",
    "\n",
    "##########    taking data from other sheets    #############\n",
    "sheets_names = ['SiO2-air-rings-4-dBYp-0.8', 'SiO2-air-rings-4-dBYp-0.9', \n",
    "                'SiO2-air-rings-4-dBYp-0.7', 'SiO2-air-rings-5-dBYp-0.6', \n",
    "                'SiO2-air-rings-5-dBYp-0.8', 'SiO2-air-rings-5-dBYp-0.9',\n",
    "                'SiO2-air-rings-4-dBYp-0.6']\n",
    "# sheets_names = []\n",
    "for sheet_name in sheets_names:\n",
    "    print(sheet_name)\n",
    "    df_sheet_name = pd.read_excel('pcf_modeSoln_data_1.xlsx', sheetname=sheet_name)\n",
    "    datafile_sheet_name = df_sheet_name.values                  ## stored data from xlsx file\n",
    "    #print(datafile_sheet_name)\n",
    "    #########    combining data from all sheets of excel file    #########\n",
    "    datafile_1 = np.concatenate((datafile_1, datafile_sheet_name), axis=0)\n",
    "\n",
    "\n",
    "print(datafile_1)\n",
    "print(len(datafile_1))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "########   just to see output variable values   ##########\n",
    "out_var_datafile_1 = datafile_1[:,range(6,11)]              ## stored output_variable (4th column) from xlsx file\n",
    "out_var_datafile_1 = out_var_datafile_1.reshape((-1,no_of_output_nodes))    ## one column with unknown no. of rows\n",
    "print(out_var_datafile_1)\n",
    "print('no. of training points: ', len(out_var_datafile_1))\n",
    "\n",
    "\n",
    "scaler1.fit(datafile_1)\n",
    "scaler2.fit(out_var_datafile_1)\n",
    "\n",
    "\n",
    "scaler_datafile_1 = scaler1.transform(datafile_1)\n",
    "X = scaler_datafile_1[:,range(0,6)]                 ## input variables columns\n",
    "y = scaler_datafile_1[:,range(6,11)]                          ## output variables columns\n",
    "\n",
    "print(X)\n",
    "print()\n",
    "print(y)\n",
    "\n",
    "\n",
    "X, y = shuffle(X, y)\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size = 0.1)\n",
    "X_train = X_train.reshape(-1, 6)                                ## 2nd column value is = no. of input variables columns\n",
    "y_train = y_train.reshape(-1, no_of_output_nodes)               ## 2nd column value is = no. of output variables columns\n",
    "X_validation = X_validation.reshape(-1, 6)                      ## 2nd column value is = no. of input variables columns\n",
    "y_validation = y_validation.reshape(-1, no_of_output_nodes)     ## 2nd column value is = no. of output variables columns\n",
    "print('no. of training points: ', len(X_train))\n",
    "print('no. of validation points: ', len(X_validation))\n",
    "\n",
    "\n",
    "###########     manual testing    #########\n",
    "df_2 = pd.read_excel('pcf_modeSoln_data_manual_1.xlsx', sheetname='Sheet1')\n",
    "datafile_2 = df_2.values                  ## stored data from xlsx file\n",
    "print(datafile_2)\n",
    "scaler_datafile_2 = scaler1.transform(datafile_2)\n",
    "X_test = scaler_datafile_2[:,range(0,6)]            ## input variables columns\n",
    "y_test = scaler_datafile_2[:,range(6,11)]                     ## output variables columns\n",
    "print(X_test)\n",
    "print()\n",
    "print(y_test)\n",
    "print('no. of test points: ', len(X_test))\n",
    "X_test = X_test.reshape(-1, 6)                      ## 2nd column value is = no. of input variables columns\n",
    "y_test = y_test.reshape(-1, no_of_output_nodes)     ## 2nd column value is = no. of output variables columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c04d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_dim = 6                                       ## = no. of input variables columns\n",
    "output_dim = no_of_output_nodes                     ## = no. of output variables columns\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# ############     model without dropout     #####################\n",
    "# nodes_hidden_1 = 20\n",
    "# nodes_hidden_2 = 20\n",
    "# ## nn.Linear() is fully connected layer\n",
    "# model = nn.Sequential(OrderedDict([\n",
    "#                         ('fc1', nn.Linear(input_dim, nodes_hidden_1)),\n",
    "#                         ('relu', nn.ReLU()),\n",
    "#                         ('fc2', nn.Linear(nodes_hidden_1, nodes_hidden_2)),\n",
    "#                         ('relu', nn.ReLU()),\n",
    "#                         ('fc3', nn.Linear(nodes_hidden_2, output_dim)),\n",
    "#                         ]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############     model with dropout - 3 layers    #####################\n",
    "####             dropout_prob leads to variations in mse curve      #########\n",
    "dropout_prob = 0.0\n",
    "nodes_hidden_1 = 50\n",
    "nodes_hidden_2 = 50\n",
    "nodes_hidden_3 = 50\n",
    "## nn.Linear() is fully connected layer\n",
    "model = nn.Sequential(OrderedDict([\n",
    "                        ('fc1', nn.Linear(input_dim, nodes_hidden_1)),\n",
    "                        ('relu', nn.ReLU()),\n",
    "                        ('dropout', nn.Dropout(dropout_prob)),\n",
    "                        ('fc2', nn.Linear(nodes_hidden_1, nodes_hidden_2)),\n",
    "                        ('relu', nn.ReLU()),\n",
    "                        ('dropout', nn.Dropout(dropout_prob)),\n",
    "                        ('fc3', nn.Linear(nodes_hidden_2, nodes_hidden_3)),\n",
    "                        ('relu', nn.ReLU()),\n",
    "                        ('dropout', nn.Dropout(dropout_prob)),\n",
    "                        ('fc4', nn.Linear(nodes_hidden_3, output_dim)),\n",
    "                        ]))\n",
    "\n",
    "\n",
    "\n",
    "# ############     model with dropout - 2 layers     #####################\n",
    "# ####             dropout_prob leads to variations in mse curve    ###########\n",
    "# dropout_prob = 0.1           # 0.5 - used in nvidia model-behavioural cloning\n",
    "# nodes_hidden_1 = 50\n",
    "# nodes_hidden_2 = 50\n",
    "# ## nn.Linear() is fully connected layer\n",
    "# model = nn.Sequential(OrderedDict([\n",
    "#                         ('fc1', nn.Linear(input_dim, nodes_hidden_1)),\n",
    "#                         ('relu', nn.ReLU()),\n",
    "#                         ('dropout', nn.Dropout(dropout_prob)),\n",
    "#                         ('fc2', nn.Linear(nodes_hidden_1, nodes_hidden_2)),\n",
    "#                         ('relu', nn.ReLU()),\n",
    "#                         ('dropout', nn.Dropout(dropout_prob)),\n",
    "#                         ('fc3', nn.Linear(nodes_hidden_2, output_dim)),\n",
    "#                         ]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(model)\n",
    "# model.double()\n",
    "# print(X_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(device)\n",
    "## move model to gpu if available, else cpu\n",
    "# model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "epochs = 5000\n",
    "# Convert numpy array to torch Variable\n",
    "# inputs = torch.from_numpy(X_train).requires_grad_()\n",
    "# labels = torch.from_numpy(y_train)\n",
    "inputs = torch.Tensor((X_train))\n",
    "labels = torch.Tensor((y_train))\n",
    "inputs_validation = torch.Tensor((X_validation))\n",
    "labels_validation = torch.Tensor((y_validation))\n",
    "running_loss = []\n",
    "running_loss_validation = []\n",
    "for epoch in range(epochs):\n",
    "    epoch += 1\n",
    "        \n",
    "    #################   train the model   ######################\n",
    "    model.train()    # prep model for training\n",
    "    # Clear gradients w.r.t. parameters, else gradients will be added up with every previous pass\n",
    "    optimizer.zero_grad() \n",
    "    # Forward to get output\n",
    "    outputs = model(inputs)\n",
    "    # Calculate Loss\n",
    "    loss = criterion(outputs, labels)       ## mean squared error\n",
    "    # Getting gradients w.r.t. parameters\n",
    "    loss.backward()\n",
    "    # Updating parameters\n",
    "    optimizer.step()         ## take a step with optimizer to update the weights\n",
    "    running_loss.append(loss.item())\n",
    "\n",
    "    \n",
    "    \n",
    "    # ###############    validate the model (not showing fluctuations)      ###################\n",
    "    # # Turn off gradients for validation, saves memory and computations\n",
    "    # with torch.no_grad():\n",
    "    #     ## this turns off dropout for evaluation mode of model\n",
    "    #     model.eval()      # prep model for evaluation\n",
    "    #     outputs_validation = model(inputs_validation)\n",
    "    #     loss_validation = criterion(outputs_validation, labels_validation)\n",
    "    #     running_loss_validation.append(loss_validation.item())\n",
    "    \n",
    "\n",
    "\n",
    "    # ###############    validate the model (showing fluctuations)      ###################\n",
    "    outputs_validation = model(inputs_validation)\n",
    "    loss_validation = criterion(outputs_validation, labels_validation)\n",
    "    running_loss_validation.append(loss_validation.item())\n",
    "        \n",
    "    \n",
    "\n",
    "    print('epoch: {}, mse_loss: {:.6f}, mse_loss_validation: {:.6f}'.format(epoch, loss.item(), loss_validation.item()))\n",
    "    # print(mean_squared_error(outputs_validation,labels_validation))\n",
    "\n",
    "\n",
    "\n",
    "    # if (epoch == 1000):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_1000.pth')\n",
    "    # elif (epoch == 2500):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_2500.pth')\n",
    "    # elif (epoch == 5000):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_5000.pth')        \n",
    "    # elif (epoch == 7500):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_7500.pth')        \n",
    "    # elif (epoch == 10000):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_10000.pth')        \n",
    "    # elif (epoch == 12500):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_12500.pth')        \n",
    "    # elif (epoch == 15000):\n",
    "    #     torch.save(model.state_dict(), 'checkpoint_15000.pth')        \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "# save the model, as weights & parameters are stored in model.state_dict()\n",
    "# print(model.state_dict().keys())\n",
    "# print(model.state_dict())\n",
    "#### torch.save(model.state_dict(), 'checkpoint-epochs-{}.pth'.format(epochs))\n",
    "torch.save(model.state_dict(), 'checkpoint.pth')\n",
    "# # load the saved model at particular epochs to compare\n",
    "state_dict = torch.load('checkpoint_5000.pth')\n",
    "# load the saved model\n",
    "#### state_dict = torch.load('checkpoint-epochs-{}.pth'.format(epochs))\n",
    "# state_dict = torch.load('checkpoint.pth')\n",
    "# state_dict = torch.load('checkpoint-simple_waveguide_neff_pytorch_1_epochs-5000.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Purely inference\n",
    "# predicted_on_X_train = model(torch.Tensor(X_train).requires_grad_()).data.numpy()\n",
    "# predicted_on_X_validation = model(torch.Tensor(X_validation).requires_grad_()).data.numpy()\n",
    "# predicted_on_X_test = model(torch.Tensor(X_test).requires_grad_()).data.numpy()\n",
    "with torch.no_grad():\n",
    "    ## this turns off dropout for evaluation mode of model\n",
    "    model.eval()\n",
    "    predicted_on_X_train = model(torch.Tensor(X_train)).data.numpy()\n",
    "    predicted_on_X_validation = model(torch.Tensor(X_validation)).data.numpy()\n",
    "    predicted_on_X_test = model(torch.Tensor(X_test)).data.numpy()\n",
    "    # print(predicted)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print('end_time: ', end_time)\n",
    "print('time taken to train in sec: ', (end_time - start_time))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## make axis bold\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mse_training_interval = 10\n",
    "mse_validation_interval = 10\n",
    "running_loss = running_loss[::mse_training_interval]\n",
    "running_loss_index = [i for i in range(1, epochs, mse_training_interval)]\n",
    "running_loss_validation = running_loss_validation[::mse_validation_interval]\n",
    "running_loss_validation_index = [i for i in range(1, epochs, mse_validation_interval)]\n",
    "print('mse lengths: ', len(running_loss), len(running_loss_validation))\n",
    "# print('running_loss_index: ', running_loss_index)\n",
    "# print('running_loss_validation_index: ', running_loss_validation_index)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c10d7b5",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - neff  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ddd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('pcf - neff - (epochs-{}) - pyTorch'.format(epochs), fontsize=25, \n",
    "                color='r', fontweight='bold')     ## giving title on top of all subplots\n",
    "\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.plot(running_loss_index, running_loss, 'r-', linewidth=3, label='mse_loss_train')\n",
    "plt.plot(running_loss_validation_index, running_loss_validation, 'b-', linewidth=3, label='mse_loss_validation')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('epochs#', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(232)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_train)[:,0], 'ro', markersize=12, label='y_train')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_train)[:,0], 'b*', markersize=12, label='predicted_on_X_train')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(233)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_validation)[:,0], 'ro', markersize=12, label='y_validation')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_validation)[:,0], 'b*', markersize=12, label='predicted_on_X_validation')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(234)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_test)[:,0], 'ro', markersize=12, label='y_test')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_test)[:,0], 'b*', markersize=12, label='predicted_on_X_test')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(235)\n",
    "xx = scaler2.inverse_transform(y_train)[:,0]\n",
    "yy = scaler2.inverse_transform(predicted_on_X_train)[:,0]\n",
    "xx_validation = scaler2.inverse_transform(y_validation)[:,0]\n",
    "yy_validation = scaler2.inverse_transform(predicted_on_X_validation)[:,0]\n",
    "xx_test = scaler2.inverse_transform(y_test)[:,0]\n",
    "yy_test = scaler2.inverse_transform(predicted_on_X_test)[:,0]\n",
    "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "bubble_plot_line_x2y2 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x2y2, 'k-', linewidth=2)\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.scatter(xx, yy, label='train', marker='o', facecolors='', edgecolors='red', s=50)\n",
    "plt.scatter(xx_validation, yy_validation, label='validation', marker='o', facecolors='', edgecolors='blue', s=50)\n",
    "plt.scatter(xx_test, yy_test, label='test', marker='o', facecolors='', edgecolors='black', s=50)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('true-values', fontsize=15)\n",
    "plt.ylabel('predicted', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(236)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,0]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,0]\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10);\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"o/p of test set:           \\n\", (scaler2.inverse_transform(y_test)[:,0]))\n",
    "print(\"predicted o/p of test set: \\n\", (scaler2.inverse_transform(predicted_on_X_test)[:,0]))\n",
    "print(\"mse_test_set: \", mean_squared_error(y_test, predicted_on_X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4446ead9",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - Aeff  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e829b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('pcf - Aeff - (epochs-{}) - pyTorch'.format(epochs), fontsize=25, \n",
    "                color='r', fontweight='bold')     ## giving title on top of all subplots\n",
    "\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.plot(running_loss_index, running_loss, 'r-', linewidth=3, label='mse_loss_train')\n",
    "plt.plot(running_loss_validation_index, running_loss_validation, 'b-', linewidth=3, label='mse_loss_validation')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('epochs#', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(232)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_train)[:,1], 'ro', markersize=12, label='y_train')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_train)[:,1], 'b*', markersize=12, label='predicted_on_X_train')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(233)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_validation)[:,1], 'ro', markersize=12, label='y_validation')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_validation)[:,1], 'b*', markersize=12, label='predicted_on_X_validation')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(234)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_test)[:,1], 'ro', markersize=12, label='y_test')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_test)[:,1], 'b*', markersize=12, label='predicted_on_X_test')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(235)\n",
    "xx = scaler2.inverse_transform(y_train)[:,1]\n",
    "yy = scaler2.inverse_transform(predicted_on_X_train)[:,1]\n",
    "xx_validation = scaler2.inverse_transform(y_validation)[:,1]\n",
    "yy_validation = scaler2.inverse_transform(predicted_on_X_validation)[:,1]\n",
    "xx_test = scaler2.inverse_transform(y_test)[:,1]\n",
    "yy_test = scaler2.inverse_transform(predicted_on_X_test)[:,1]\n",
    "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "bubble_plot_line_x2y2 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x2y2, 'k-', linewidth=2)\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.scatter(xx, yy, label='train', marker='o', facecolors='', edgecolors='red', s=50)\n",
    "plt.scatter(xx_validation, yy_validation, label='validation', marker='o', facecolors='', edgecolors='blue', s=50)\n",
    "plt.scatter(xx_test, yy_test, label='test', marker='o', facecolors='', edgecolors='black', s=50)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('true-values', fontsize=15)\n",
    "plt.ylabel('predicted', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(236)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,1]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,1]\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10);\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"o/p of test set:           \\n\", (scaler2.inverse_transform(y_test)[:,1]))\n",
    "print(\"predicted o/p of test set: \\n\", (scaler2.inverse_transform(predicted_on_X_test)[:,1]))\n",
    "print(\"mse_test_set: \", mean_squared_error(y_test, predicted_on_X_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c29478",
   "metadata": {
    "cell_marker": "# ####################################################################################################"
   },
   "source": [
    "###########    saving predicted data to excel file   ##############\n",
    "plt.show()\n",
    "n1 = xx\n",
    "n2 = yy\n",
    "n3 = true_values\n",
    "n4 = predicted_values\n",
    "n5 = error_values\n",
    "## convert your array into a dataframe\n",
    "# df = pd.DataFrame(l1, columns=['a'])\n",
    "df1 = pd.DataFrame(OrderedDict({'y_train':n1, 'predicted_on_X_train':n2}))\n",
    "df2 = pd.DataFrame({'y_test':n3, 'predicted_on_X_test':n4, 'error_values':n5}, \n",
    "                        columns=['y_test', 'predicted_on_X_test', 'error_values'])\n",
    "## save to xlsx file\n",
    "# filepath_1 = 'test_excel_file_1.xlsx'\n",
    "df1.to_excel('test_excel_file_1.xlsx', sheet_name='sheet1', index=False)\n",
    "df2.to_excel('test_excel_file_2.xlsx', sheet_name='sheet1', index=False)\n",
    "# sys.exit()\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207472df",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - disp  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683eb796",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('pcf - disp - (epochs-{}) - pyTorch'.format(epochs), fontsize=25, \n",
    "                color='r', fontweight='bold')     ## giving title on top of all subplots\n",
    "\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.plot(running_loss_index, running_loss, 'r-', linewidth=3, label='mse_loss_train')\n",
    "plt.plot(running_loss_validation_index, running_loss_validation, 'b-', linewidth=3, label='mse_loss_validation')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('epochs#', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(232)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_train)[:,2], 'ro', markersize=12, label='y_train')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_train)[:,2], 'b*', markersize=12, label='predicted_on_X_train')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(233)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_validation)[:,2], 'ro', markersize=12, label='y_validation')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_validation)[:,2], 'b*', markersize=12, label='predicted_on_X_validation')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(234)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_test)[:,2], 'ro', markersize=12, label='y_test')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_test)[:,2], 'b*', markersize=12, label='predicted_on_X_test')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(235)\n",
    "xx = scaler2.inverse_transform(y_train)[:,2]\n",
    "yy = scaler2.inverse_transform(predicted_on_X_train)[:,2]\n",
    "xx_validation = scaler2.inverse_transform(y_validation)[:,2]\n",
    "yy_validation = scaler2.inverse_transform(predicted_on_X_validation)[:,2]\n",
    "xx_test = scaler2.inverse_transform(y_test)[:,2]\n",
    "yy_test = scaler2.inverse_transform(predicted_on_X_test)[:,2]\n",
    "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "bubble_plot_line_x2y2 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x2y2, 'k-', linewidth=2)\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.scatter(xx, yy, label='train', marker='o', facecolors='', edgecolors='red', s=50)\n",
    "plt.scatter(xx_validation, yy_validation, label='validation', marker='o', facecolors='', edgecolors='blue', s=50)\n",
    "plt.scatter(xx_test, yy_test, label='test', marker='o', facecolors='', edgecolors='black', s=50)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('true-values', fontsize=15)\n",
    "plt.ylabel('predicted', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(236)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,2]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,2]\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10);\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"o/p of test set:           \\n\", (scaler2.inverse_transform(y_test)[:,2]))\n",
    "print(\"predicted o/p of test set: \\n\", (scaler2.inverse_transform(predicted_on_X_test)[:,2]))\n",
    "print(\"mse_test_set: \", mean_squared_error(y_test, predicted_on_X_test))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13acb59b",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - conf-loss  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7da68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('pcf - conf_loss - (epochs-{}) - pyTorch'.format(epochs), fontsize=25, \n",
    "                color='r', fontweight='bold')     ## giving title on top of all subplots\n",
    "\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.plot(running_loss_index, running_loss, 'r-', linewidth=3, label='mse_loss_train')\n",
    "plt.plot(running_loss_validation_index, running_loss_validation, 'b-', linewidth=3, label='mse_loss_validation')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('epochs#', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(232)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_train)[:,3], 'ro', markersize=12, label='y_train')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_train)[:,3], 'b*', markersize=12, label='predicted_on_X_train')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(233)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_validation)[:,3], 'ro', markersize=12, label='y_validation')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_validation)[:,3], 'b*', markersize=12, label='predicted_on_X_validation')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(234)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_test)[:,3], 'ro', markersize=12, label='y_test')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_test)[:,3], 'b*', markersize=12, label='predicted_on_X_test')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(235)\n",
    "xx = scaler2.inverse_transform(y_train)[:,3]\n",
    "yy = scaler2.inverse_transform(predicted_on_X_train)[:,3]\n",
    "xx_validation = scaler2.inverse_transform(y_validation)[:,3]\n",
    "yy_validation = scaler2.inverse_transform(predicted_on_X_validation)[:,3]\n",
    "xx_test = scaler2.inverse_transform(y_test)[:,3]\n",
    "yy_test = scaler2.inverse_transform(predicted_on_X_test)[:,3]\n",
    "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "bubble_plot_line_x2y2 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x2y2, 'k-', linewidth=2)\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.scatter(xx, yy, label='train', marker='o', facecolors='', edgecolors='red', s=50)\n",
    "plt.scatter(xx_validation, yy_validation, label='validation', marker='o', facecolors='', edgecolors='blue', s=50)\n",
    "plt.scatter(xx_test, yy_test, label='test', marker='o', facecolors='', edgecolors='black', s=50)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('true-values', fontsize=15)\n",
    "plt.ylabel('predicted', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(236)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,3]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,3]\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10);\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"o/p of test set:           \\n\", (scaler2.inverse_transform(y_test)[:,3]))\n",
    "print(\"predicted o/p of test set: \\n\", (scaler2.inverse_transform(predicted_on_X_test)[:,3]))\n",
    "print(\"mse_test_set: \", mean_squared_error(y_test, predicted_on_X_test))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b23a9a2",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - conf-loss-in-log10  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.suptitle('pcf - conf_loss_in_log10 - (epochs-{}) - pyTorch'.format(epochs), fontsize=25, \n",
    "                color='r', fontweight='bold')     ## giving title on top of all subplots\n",
    "\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.plot(running_loss_index, running_loss, 'r-', linewidth=3, label='mse_loss_train')\n",
    "plt.plot(running_loss_validation_index, running_loss_validation, 'b-', linewidth=3, label='mse_loss_validation')\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('epochs#', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(232)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_train)[:,4], 'ro', markersize=12, label='y_train')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_train)[:,4], 'b*', markersize=12, label='predicted_on_X_train')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(233)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_validation)[:,4], 'ro', markersize=12, label='y_validation')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_validation)[:,4], 'b*', markersize=12, label='predicted_on_X_validation')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(234)\n",
    "# Plot true data\n",
    "plt.plot(scaler2.inverse_transform(y_test)[:,4], 'ro', markersize=12, label='y_test')\n",
    "# Plot predictions\n",
    "plt.plot(scaler2.inverse_transform(predicted_on_X_test)[:,4], 'b*', markersize=12, label='predicted_on_X_test')\n",
    "# Legend and plot\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(235)\n",
    "xx = scaler2.inverse_transform(y_train)[:,4]\n",
    "yy = scaler2.inverse_transform(predicted_on_X_train)[:,4]\n",
    "xx_validation = scaler2.inverse_transform(y_validation)[:,4]\n",
    "yy_validation = scaler2.inverse_transform(predicted_on_X_validation)[:,4]\n",
    "xx_test = scaler2.inverse_transform(y_test)[:,4]\n",
    "yy_test = scaler2.inverse_transform(predicted_on_X_test)[:,4]\n",
    "bubble_plot_line_x1y1 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "bubble_plot_line_x2y2 = [min(np.minimum(xx,yy)), max(np.maximum(xx,yy))]\n",
    "plt.xlim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.ylim(bubble_plot_line_x1y1[0], bubble_plot_line_x1y1[1])\n",
    "plt.plot(bubble_plot_line_x1y1, bubble_plot_line_x2y2, 'k-', linewidth=2)\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.scatter(xx, yy, label='train', marker='o', facecolors='', edgecolors='red', s=50)\n",
    "plt.scatter(xx_validation, yy_validation, label='validation', marker='o', facecolors='', edgecolors='blue', s=50)\n",
    "plt.scatter(xx_test, yy_test, label='test', marker='o', facecolors='', edgecolors='black', s=50)\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "plt.xlabel('true-values', fontsize=15)\n",
    "plt.ylabel('predicted', fontsize=15)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "plt.subplot(236)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,4]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,4]\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10);\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"o/p of test set:           \\n\", (scaler2.inverse_transform(y_test)[:,4]))\n",
    "print(\"predicted o/p of test set: \\n\", (scaler2.inverse_transform(predicted_on_X_test)[:,4]))\n",
    "print(\"mse_test_set: \", mean_squared_error(y_test, predicted_on_X_test))\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d156c64",
   "metadata": {
    "cell_marker": "###############################################################"
   },
   "source": [
    "################   plotting graphs together - conf-loss-without/with-log10  ################\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811e9f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "true_values = scaler2.inverse_transform(y_test)[:,3]\n",
    "predicted_values = scaler2.inverse_transform(predicted_on_X_test)[:,3]\n",
    "print(true_values)\n",
    "print(predicted_values)\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10)\n",
    "plt.yscale('log')\n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.title('conf-loss-without-log10', fontsize=25)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "true_values = 10**(scaler2.inverse_transform(y_test)[:,4])\n",
    "predicted_values = 10**(scaler2.inverse_transform(predicted_on_X_test)[:,4])\n",
    "print(true_values)\n",
    "print(predicted_values)\n",
    "x_index = [i for i in range(len(true_values))]\n",
    "error_values = predicted_values - true_values\n",
    "plt.errorbar(x=x_index, y=true_values, yerr=error_values, fmt='o', color='black', \n",
    "                    ecolor='black', elinewidth=2, capsize=10)\n",
    "plt.yscale('log')                    \n",
    "plt.grid(linestyle='--', linewidth=1)\n",
    "plt.title('conf-loss-with-log10', fontsize=25)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d3a0b",
   "metadata": {
    "cell_marker": "# ####################################################################################################"
   },
   "source": [
    "###########    saving predicted data to excel file   ##############\n",
    "plt.show()\n",
    "n1 = xx\n",
    "n2 = yy\n",
    "n3 = true_values\n",
    "n4 = predicted_values\n",
    "n5 = error_values\n",
    "## convert your array into a dataframe\n",
    "# df = pd.DataFrame(l1, columns=['a'])\n",
    "df1 = pd.DataFrame(OrderedDict({'y_train':n1, 'predicted_on_X_train':n2}))\n",
    "df2 = pd.DataFrame({'y_test':n3, 'predicted_on_X_test':n4, 'error_values':n5}, \n",
    "                        columns=['y_test', 'predicted_on_X_test', 'error_values'])\n",
    "## save to xlsx file\n",
    "# filepath_1 = 'test_excel_file_1.xlsx'\n",
    "df1.to_excel('test_excel_file_1.xlsx', sheet_name='sheet1', index=False)\n",
    "df2.to_excel('test_excel_file_2.xlsx', sheet_name='sheet1', index=False)\n",
    "# sys.exit()\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37745508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###########    saving predicted data to excel file   ##############\n",
    "l1 = 10**(scaler2.inverse_transform(y_test)[:,4])                     #### check multiple of 10\n",
    "l2 = 10**(scaler2.inverse_transform(predicted_on_X_test)[:,4])        #### check multiple of 10\n",
    "###########    saving mse data to excel file   ##############\n",
    "l3 = running_loss\n",
    "l4 = running_loss_validation\n",
    "l5 = running_loss_index\n",
    "l6 = running_loss_validation_index\n",
    "\n",
    "## convert your array into a dataframe\n",
    "# df = pd.DataFrame(l1, columns=['a'])\n",
    "df = pd.DataFrame({'a':l3, 'b':l4})\n",
    "\n",
    "## save to xlsx file\n",
    "filepath = 'test_excel_file.xlsx'\n",
    "df.to_excel(filepath, sheet_name='sheet1', index=False)\n",
    "\n",
    "\n",
    "# sys.exit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dee2c5",
   "metadata": {
    "cell_marker": "##########################################"
   },
   "source": [
    "######           GUI           ##########\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db011551",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 3))\n",
    "fig = plt.gcf()      # if using Pyplot then get the figure from the plot\n",
    "figure_x, figure_y, figure_w, figure_h = fig.bbox.bounds\n",
    "print(figure_w)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e24316",
   "metadata": {
    "cell_marker": "\"\"\"",
    "lines_to_next_cell": 1
   },
   "source": [
    "Demonstrates one way of embedding Matplotlib figures into a PySimpleGUI window.\n",
    "Basic steps are:\n",
    " * Create a Canvas Element\n",
    " * Layout form\n",
    " * Display form (NON BLOCKING)\n",
    " * Draw plots onto convas\n",
    " * Display form (BLOCKING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff4acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_figure(canvas, figure, loc=(0, 0)):\n",
    "    \"\"\" Draw a matplotlib figure onto a Tk canvas\n",
    "    loc: location of top-left corner of figure on canvas in pixels.\n",
    "    Inspired by matplotlib source: lib/matplotlib/backends/backend_tkagg.py\n",
    "    \"\"\"\n",
    "    figure_canvas_agg = FigureCanvasAgg(figure)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_x, figure_y, figure_w, figure_h = figure.bbox.bounds\n",
    "    figure_w, figure_h = int(figure_w), int(figure_h)\n",
    "    photo = Tk.PhotoImage(master=canvas, width=figure_w, height=figure_h)\n",
    "    canvas.create_image(loc[0] + figure_w/2, loc[1] + figure_h/2, image=photo)\n",
    "    tkagg.blit(photo, figure_canvas_agg.get_renderer()._renderer, colormode=2)\n",
    "    return photo\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [\n",
    "    sg.Image(filename='hexagonal_pcf_image.PNG', size=(250, 250)),\n",
    "    sg.Text('\\n Hexagonal \\n PCF', size=(15, 4), background_color='orange', justification='center', font=(\"Helvetica\", 40), relief=sg.RELIEF_RIDGE)],\n",
    "    [sg.Text('_'  * 100)],\n",
    "    [sg.Frame('Material',[\n",
    "        # [sg.Text('')],\n",
    "        [sg.Text('Core  ', font=(\"Helvetica\", 20), text_color=''), sg.Radio('Silica', \"RADIO1\", default=True, key='core_silica'), \n",
    "        # sg.Radio('ChG', \"RADIO1\", key='core_ChG')\n",
    "        ],\n",
    "        # [sg.Text('')],\n",
    "        [sg.Text('Holes ', font=(\"Helvetica\", 20), text_color=''), sg.Radio('Air', \"RADIO2\", default=True, key='holes_air')],\n",
    "\t\t], font=(\"Helvetica\", 20), title_color='blue'),\n",
    "    sg.Frame('Wavelength (um)',[\n",
    "\t\t[sg.Slider(range=(0.5, 1.8), resolution=0.005, orientation='h', size=(15, 20), default_value=1.55, key='wavelength')]], font=(\"Helvetica\", 20), title_color='blue'),\n",
    "    sg.Frame('Parameters',[\n",
    "        [sg.Text('No. of Rings', font=(\"Helvetica\", 20), text_color=''), sg.Radio('4', \"RADIO3\", default=True, key='no_of_rings_4'), sg.Radio('5', \"RADIO3\", key='no_of_rings_5')],\n",
    " \t\t[sg.Text('Pitch (um)  ', font=(\"Helvetica\", 20), text_color=''), sg.Slider(range=(0.8, 2), resolution=0.1, orientation='h', size=(15, 20), default_value=1.5, key='pitch')],\n",
    "        [sg.Text('Dia by Pitch', font=(\"Helvetica\", 20), text_color=''), sg.Radio('0.6', \"RADIO4\", key='diaBYpitch_0.6'), sg.Radio('0.7', \"RADIO4\", default=True, key='diaBYpitch_0.7'),],\n",
    " \t\t[sg.Text('                  ', font=(\"Helvetica\", 20),), sg.Radio('0.8', \"RADIO4\", key='diaBYpitch_0.8'), sg.Radio('0.9', \"RADIO4\", key='diaBYpitch_0.9'),]\n",
    "        ], font=(\"Helvetica\", 20), title_color='blue')\n",
    "        ],\n",
    "    [sg.Text('_'  * 100)],    \n",
    "    [sg.Button('Calculate', tooltip='Click to calculate various values...', button_color=('white', 'green'), size=(10,2), font=(\"Helvetica\", 25)),\n",
    "    sg.Text(' '  * 8),\n",
    "    sg.Frame('neff',[[\n",
    "\t\tsg.Multiline(default_text=' ', key='neff', size=(10, 3))\n",
    "\t\t]], font=(\"Helvetica\", 10), title_color='red'),\n",
    "    sg.Frame('Aeff (um^2)',[[\n",
    "\t\tsg.Multiline(default_text=' ', key='Aeff', size=(10, 3))\n",
    "\t\t]], font=(\"Helvetica\", 10), title_color='red'),\n",
    "    sg.Frame('Disp (ps/Km.nm)',[[\n",
    "\t\tsg.Multiline(default_text=' ', key='disp', size=(10, 3))\n",
    "\t\t]], font=(\"Helvetica\", 10), title_color='red'),\n",
    "    # sg.Frame('Lc (dB/cm)',[[\n",
    "\t# \tsg.Multiline(default_text=' ', key='conf_loss', size=(10, 3))\n",
    "\t# \t]], font=(\"Helvetica\", 10), title_color='red'),\n",
    "    sg.Frame('Lc-using-Log (dB/cm)',[[\n",
    "\t\tsg.Multiline(default_text=' ', key='conf_loss_using_log', size=(10, 3))\n",
    "\t\t]], font=(\"Helvetica\", 10), title_color='red'),    \n",
    "    # sg.Canvas(size=(figure_w, figure_h), key='canvas')    \n",
    "    ],\n",
    "    [sg.Button('Exit', tooltip='Click to exit the window...', button_color=('black', 'red'), size=(10,2), font=(\"Helvetica\", 15))]\n",
    "]\n",
    "\n",
    "window = sg.Window('PCF', layout, location=(400,25), \n",
    "\t\t\t\t\t\tdefault_element_size=(40, 1), grab_anywhere=False,\n",
    "\t\t\t\t\t\tresizable=True, background_color=None, font=(\"Helvetica\", 13))\n",
    "\n",
    "# event, values = window.Read()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calculate_values():\n",
    "    \n",
    "    print()\n",
    "    print('core_silica: ', values['core_silica'])\n",
    "    # print('core_ChG: ', values['core_ChG'])\n",
    "    print('holes_air: ', values['holes_air'])\n",
    "    print('wavelength (um): ', values['wavelength'])\n",
    "    print('no_of_rings_4: ', values['no_of_rings_4'])\n",
    "    print('no_of_rings_5: ', values['no_of_rings_5'])\n",
    "    print('pitch (um)    : ', values['pitch'])\n",
    "    print('diaBYpitch_0.6: ', values['diaBYpitch_0.6'])\n",
    "    print('diaBYpitch_0.7: ', values['diaBYpitch_0.7'])\n",
    "    print('diaBYpitch_0.8: ', values['diaBYpitch_0.8'])\n",
    "    print('diaBYpitch_0.9: ', values['diaBYpitch_0.9'])\n",
    "\n",
    "\n",
    "    if (values['core_silica'] == True):\n",
    "        core_ref = 1.444\n",
    "    # elif (values['core_ChG'] == True):\n",
    "    #     core_ref = 2.567  \n",
    "\n",
    "    if (values['holes_air'] == True):\n",
    "        holes_ref = 1.0\n",
    "    \n",
    "    if (values['no_of_rings_4'] == True):\n",
    "        no_of_rings = 4\n",
    "    elif (values['no_of_rings_5'] == True):\n",
    "        no_of_rings = 5\n",
    "        \n",
    "    \n",
    "    if (values['diaBYpitch_0.6'] == True):\n",
    "        diaBYpitch = 0.6\n",
    "    elif (values['diaBYpitch_0.7'] == True):\n",
    "        diaBYpitch = 0.7\n",
    "    elif (values['diaBYpitch_0.8'] == True):\n",
    "        diaBYpitch = 0.8\n",
    "    elif (values['diaBYpitch_0.9'] == True):\n",
    "        diaBYpitch = 0.9\n",
    "    \n",
    "\n",
    "    ###########     manual testing from GUI   #########\n",
    "    #### [[ core_ref, holes_ref, no_of_rings, diaBYpitch, wavelength, pitch,  zero-neff, zero-Aeff, zero-disp, zero-conf-loss, zero-conf-loss-in-log]]\n",
    "    datafile_3 = np.array([[core_ref, holes_ref, no_of_rings, diaBYpitch, values['wavelength'], values['pitch'],  0, 0, 0, 0, 0]])\n",
    "    scaler_datafile_3 = scaler1.transform(datafile_3)\n",
    "    X_test_GUI = scaler_datafile_3[:,range(0,6)]\n",
    "    print(datafile_3)\n",
    "    print(X_test_GUI)\n",
    "    ###################################################\n",
    "\n",
    "    predicted_on_X_test_GUI = model(torch.Tensor(X_test_GUI)).data.numpy()\n",
    "    print(\"\\npredicted o/p of test set GUI: \\n\", scaler2.inverse_transform(predicted_on_X_test_GUI))\n",
    "    \n",
    "    print(predicted_on_X_test_GUI)\n",
    "    print(scaler2.inverse_transform(predicted_on_X_test_GUI))\n",
    "    print(scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,0), \n",
    "            scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,1),\n",
    "            scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,2))\n",
    "    X_test_GUI_neff = round(scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,0), 5)\n",
    "    X_test_GUI_Aeff = round(scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,1), 5)\n",
    "    X_test_GUI_disp = round(scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,2), 5)\n",
    "    X_test_GUI_confLoss = format((scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,3)), '4E')\n",
    "    ##### taking antilog to get the predicted conf loss (not in log values)   #####\n",
    "    #####   use 'e or g, E or G'  for exponential format   ##### \n",
    "    X_test_GUI_confLossUsingLog = format(10**(scaler2.inverse_transform(predicted_on_X_test_GUI).item(0,4)), '.5E')\n",
    "    print(X_test_GUI_neff, X_test_GUI_Aeff, X_test_GUI_disp, X_test_GUI_confLoss, X_test_GUI_confLossUsingLog)\n",
    "    return X_test_GUI_neff, X_test_GUI_Aeff, X_test_GUI_disp, X_test_GUI_confLoss, X_test_GUI_confLossUsingLog\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:                 # Event Loop\n",
    "    event, values = window.Read()\n",
    "    # sg.Popup('The results of the window-- ',\n",
    "\t# \t\t'The button clicked was \"{}\"'.format(event),\n",
    "\t# \t\t'The values are: ', values)\n",
    "\n",
    "    if event is None or event == 'Exit':\n",
    "        break\n",
    "    if event == 'Calculate':\n",
    "        X_test_GUI_updated = calculate_values()\n",
    "        # change the \"output\" element to be the value of \"input\" element\n",
    "        window.FindElement('neff').Update(X_test_GUI_updated[0])\n",
    "        window.FindElement('Aeff').Update(X_test_GUI_updated[1])\n",
    "        window.FindElement('disp').Update(X_test_GUI_updated[2])\n",
    "        # window.FindElement('conf_loss').Update(X_test_GUI_updated[3])\n",
    "        window.FindElement('conf_loss_using_log').Update(X_test_GUI_updated[4])\n",
    "        # add the plot to the window\n",
    "        # fig_photo = draw_figure(window.FindElement('canvas').TKCanvas, fig)\n",
    "\n",
    "\n",
    "window.Close()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
